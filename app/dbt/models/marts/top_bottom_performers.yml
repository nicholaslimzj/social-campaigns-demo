version: 2

models:
  - name: top_bottom_performers
    description: "Mart model that identifies the top and bottom performing entities (companies, channels, segments) based on key marketing metrics like conversion rate, ROI, acquisition cost, and CTR. It calculates average metrics per entity, ranks them, and compares them against global averages. Company metrics are based on data from the last three available months in the source."
    config:
      materialized: table
      tags: ['mart', 'performance', 'ranking']
    columns:
      - name: dimension
        description: "The dimension being analyzed (e.g., 'company', 'channel', 'segment')."
        tests:
          - not_null
          - accepted_values:
              values: ['company', 'channel', 'segment']

      - name: entity
        description: "The specific entity within the dimension being ranked (e.g., company name, channel name, customer segment name)."
        tests:
          - not_null
          # Relationship test assumes stg_campaigns has distinct Company, Channel_Used, Customer_Segment columns
          # Note: This might be too broad if entity names can overlap across dimensions.
          # A more precise test would require separate checks per dimension value.
          # - relationships: # Example - adjust field names based on stg_campaigns structure
          #     to: ref('stg_campaigns')
          #     field: Company # This only works for dimension='company'
          # - relationships: # Example - adjust field names based on stg_campaigns structure
          #     to: ref('stg_campaigns')
          #     field: Channel_Used # This only works for dimension='channel'
          # - relationships: # Example - adjust field names based on stg_campaigns structure
          #     to: ref('stg_campaigns')
          #     field: Customer_Segment # This only works for dimension='segment'

      - name: metric
        description: "The performance metric being evaluated (e.g., 'conversion_rate', 'roi', 'acquisition_cost', 'ctr')."
        tests:
          - not_null
          - accepted_values:
              values: ['conversion_rate', 'roi', 'acquisition_cost', 'ctr']

      - name: value
        description: "The calculated value of the metric for the specific entity. This is typically an average (conversion rate, ROI, acquisition cost) or an overall calculation (CTR)."
        tests:
          - not_null # Assuming valid calculations should not result in NULL

      - name: rank
        description: "The rank of the entity for the specified metric within its dimension. Rank 1 indicates the best performance (highest for conversion rate/ROI/CTR, lowest for acquisition cost)."
        tests:
          - not_null
          - accepted_values:
              values: [1] # This model specifically filters for rank 1 (top) or rank_asc 1 (bottom), and outputs the descending rank value.

      - name: total_entities
        description: "The total number of unique entities within the dimension (e.g., total number of companies analyzed)."
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: ">= 1"

      - name: performance
        description: "Indicates whether the entity is a 'top' or 'bottom' performer for the given metric."
        tests:
          - not_null
          - accepted_values:
              values: ['top', 'bottom']

      - name: global_avg
        description: "The global average value for the specified metric across all entities in all dimensions, calculated from the stg_campaigns data."
        tests:
          - not_null # Assuming there's enough data for a global average

      - name: pct_diff_from_avg
        description: "The percentage difference between the entity's metric value and the global average for that metric. Calculated as (value / global_avg) - 1."
        # No not_null test as it could be null if global_avg is 0.

    tests:
      # Test that the combination of dimension, metric, and performance level is unique.
      # There should only be one 'top' performer and one 'bottom' performer per dimension/metric pair.
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - dimension
            - metric
            - performance